{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = Variable(torch.from_numpy(xy[:, 0:-1]))\n",
    "y_data = Variable(torch.from_numpy(xy[:, [-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 6)\n",
    "        self.l2 = torch.nn.Linear(6, 4)\n",
    "        self.l3 = torch.nn.Linear(4, 1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6830596923828125\n",
      "1 0.6789541244506836\n",
      "2 0.6753042340278625\n",
      "3 0.6720573306083679\n",
      "4 0.6691685914993286\n",
      "5 0.6665964722633362\n",
      "6 0.6643069386482239\n",
      "7 0.6622663736343384\n",
      "8 0.6604475975036621\n",
      "9 0.6588257551193237\n",
      "10 0.6573789715766907\n",
      "11 0.6560879945755005\n",
      "12 0.6549347043037415\n",
      "13 0.6539053320884705\n",
      "14 0.6529856324195862\n",
      "15 0.6521627902984619\n",
      "16 0.6514276266098022\n",
      "17 0.6507701873779297\n",
      "18 0.650181233882904\n",
      "19 0.6496545076370239\n",
      "20 0.6491830348968506\n",
      "21 0.6487609148025513\n",
      "22 0.6483820676803589\n",
      "23 0.648043155670166\n",
      "24 0.6477391123771667\n",
      "25 0.6474660634994507\n",
      "26 0.647222101688385\n",
      "27 0.6470024585723877\n",
      "28 0.6468055844306946\n",
      "29 0.6466290354728699\n",
      "30 0.6464701294898987\n",
      "31 0.6463273763656616\n",
      "32 0.6461998224258423\n",
      "33 0.6460846662521362\n",
      "34 0.645980715751648\n",
      "35 0.6458880305290222\n",
      "36 0.645804226398468\n",
      "37 0.645729124546051\n",
      "38 0.6456613540649414\n",
      "39 0.6456001400947571\n",
      "40 0.6455451846122742\n",
      "41 0.6454960107803345\n",
      "42 0.6454514265060425\n",
      "43 0.6454112529754639\n",
      "44 0.6453753709793091\n",
      "45 0.6453421711921692\n",
      "46 0.645312488079071\n",
      "47 0.645286500453949\n",
      "48 0.6452622413635254\n",
      "49 0.6452397704124451\n",
      "50 0.6452205181121826\n",
      "51 0.6452024579048157\n",
      "52 0.645186722278595\n",
      "53 0.645172119140625\n",
      "54 0.6451583504676819\n",
      "55 0.6451465487480164\n",
      "56 0.6451354026794434\n",
      "57 0.6451256275177002\n",
      "58 0.6451159715652466\n",
      "59 0.6451079845428467\n",
      "60 0.6451002955436707\n",
      "61 0.6450936794281006\n",
      "62 0.6450870037078857\n",
      "63 0.6450810432434082\n",
      "64 0.6450758576393127\n",
      "65 0.6450702548027039\n",
      "66 0.6450660228729248\n",
      "67 0.6450612545013428\n",
      "68 0.6450576782226562\n",
      "69 0.645054042339325\n",
      "70 0.6450508236885071\n",
      "71 0.6450472474098206\n",
      "72 0.6450446844100952\n",
      "73 0.6450420022010803\n",
      "74 0.6450390219688416\n",
      "75 0.6450368165969849\n",
      "76 0.6450345516204834\n",
      "77 0.6450319290161133\n",
      "78 0.6450299620628357\n",
      "79 0.6450281143188477\n",
      "80 0.645025908946991\n",
      "81 0.6450234055519104\n",
      "82 0.6450223326683044\n",
      "83 0.6450199484825134\n",
      "84 0.6450186371803284\n",
      "85 0.6450170278549194\n",
      "86 0.6450151801109314\n",
      "87 0.6450136303901672\n",
      "88 0.6450119614601135\n",
      "89 0.645010769367218\n",
      "90 0.6450089812278748\n",
      "91 0.6450073719024658\n",
      "92 0.6450062394142151\n",
      "93 0.6450048685073853\n",
      "94 0.6450035572052002\n",
      "95 0.6450021862983704\n",
      "96 0.6450005173683167\n",
      "97 0.6449994444847107\n",
      "98 0.6449979543685913\n",
      "99 0.6449968814849854\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    y_pred = model(x_data)\n",
    "    \n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
